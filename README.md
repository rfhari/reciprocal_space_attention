# Reciprocal Space Attention (RSA) for Learning Long-Range Interactions

# Abstract
Machine-learning interatomic potentials (MLIPs) fit ab initio data and excel at local interactions but often fail when explicit long-range physics is required. We introduce Reciprocal-Space Attention (RSA), a Fourier-domain module that augments existing local or semi-local MLIPs. RSA maps linear-scaling attention to reciprocal space, enabling efficient treatment of electrostatics and dispersion without predefined charges or other empirical inputs. We validate RSA on representative tasks - dimer binding curves, dispersion dominated exfoliation of layered phosphorene, and molecular dynamics of water. These results show that RSA offers a general, scalable route to incorporating long-range interactions within modern MLIPs.

